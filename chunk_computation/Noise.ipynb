{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DVv8Fwx65Ej"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import LeaveOneOut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJBzumqdlDLv",
        "outputId": "8518dfb5-b26a-4786-94dc-f1710185680a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5714025946899135\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "random.seed(10)\n",
        "print(random.random())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4N1NVmIMo32",
        "outputId": "755ba4c1-7566-4ce8-8408-bc428bb5ccd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBqeTmPj8MWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ecfba1a-5da9-4407-ccdf-4014192b13a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data_path = \"/content/drive/MyDrive/ML CS433 Project 2/data\"\n",
        "#data_path = os.path.join(os.path.dirname(os.path.normpath(os.getcwd())), \"data\")\n",
        "noise_path = os.path.join(data_path, \"demand\")\n",
        "print(os.path.exists(data_path))\n",
        "os.path.exists(noise_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4Lgy-jaSlor"
      },
      "outputs": [],
      "source": [
        "# Noise addition function\n",
        "import soundfile as sf\n",
        "def set_global_snr(clean, noise, snr_db):    \n",
        "    clean_pow = np.sum(clean**2)\n",
        "    noise_pow = np.sum(noise**2)\n",
        "    noise_scale = np.sqrt( clean_pow / (noise_pow * 10**(snr_db/10)) )\n",
        "    return noise_scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hK0FioSY4oC",
        "outputId": "294e2713-2ec6-4f10-dc48-d97c367c2495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'D': ['DLIVING', 'DKITCHEN', 'DWASHING'], 'N': ['NFIELD', 'NPARK', 'NRIVER'], 'O': ['OOFFICE', 'OHALLWAY', 'OMEETING'], 'S': ['SPSQUARE', 'SCAFE', 'STRAFFIC'], 'T': ['TMETRO', 'TBUS', 'TCAR'], 'P': ['PRESTO', 'PCAFETER', 'PSTATION']}\n"
          ]
        }
      ],
      "source": [
        "# Create a dictionary for noise categories and their environments\n",
        "noise_categories = dict()\n",
        "for env in os.listdir(noise_path):\n",
        "  if env[0] in noise_categories:\n",
        "    noise_categories[env[0]].append(env)\n",
        "  else:\n",
        "    noise_categories[env[0]] = [env]\n",
        "\n",
        "print(noise_categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn2leKk9J6SO",
        "outputId": "81adb496-b687-483b-9533-a5e046d42b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/ML CS433 Project 2/data/demand/DLIVING/ch05.wav', '/content/drive/MyDrive/ML CS433 Project 2/data/demand/OOFFICE/ch05.wav', '/content/drive/MyDrive/ML CS433 Project 2/data/demand/SPSQUARE/ch05.wav']\n",
            "['/content/drive/MyDrive/ML CS433 Project 2/data/demand/DKITCHEN/ch05.wav', '/content/drive/MyDrive/ML CS433 Project 2/data/demand/OHALLWAY/ch05.wav', '/content/drive/MyDrive/ML CS433 Project 2/data/demand/SCAFE/ch05.wav']\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "#Due to disk space usage not implementable\n",
        "def get_channels_():\n",
        "  training_channels_paths = []\n",
        "  val_environments_paths = []\n",
        "  for category, envs in noise_categories.items():\n",
        "    # Select 2 environments from each category for validation\n",
        "    val_noise_set = random.sample(envs, 2)\n",
        "    val_environments_paths.append(noise_path + '/' + val_noise_set[0] + '/' + 'ch05.wav') #maybe randomization of channel would make sense\n",
        "    val_environments_paths.append(noise_path + '/' + val_noise_set[1] + '/' + 'ch05.wav')\n",
        "    # Select the remaining environment from each category for training\n",
        "    training_noise_set = set(envs) - set(val_noise_set)\n",
        "    channels = os.listdir(noise_path + '/' + list(training_noise_set)[0])\n",
        "    # Select random channel from each environment for training\n",
        "    training_channels_paths.append(noise_path + '/' + list(training_noise_set)[0] + '/' + 'ch05.wav')\n",
        "  return val_environments_paths, training_channels_paths\n",
        "\n",
        "\n",
        "\n",
        "def get_channels():\n",
        "  train = [os.path.join(noise_path,noise,'ch05.wav') for noise in [\"DKITCHEN\",\"OHALLWAY\",\"SCAFE\"]]\n",
        "  test = [os.path.join(noise_path,noise,'ch05.wav') for noise in [\"DLIVING\",\"OOFFICE\",\"SPSQUARE\"]]\n",
        "  return test, train\n",
        "\n",
        "val_environments_paths, training_channels_paths = get_channels()\n",
        "print(val_environments_paths)\n",
        "print(training_channels_paths)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeVfJMhcJ1FH"
      },
      "outputs": [],
      "source": [
        "training_SNR = [10]\n",
        "testing_SNR = [0, 5, 10, 15, 20]\n",
        "\n",
        "def rms(sig):\n",
        "  return np.sqrt(np.mean(sig**2))\n",
        "\n",
        "def get_noisy_signal(sig, noise, snr):\n",
        "  required_rms = np.sqrt(rms(sig)/10**(snr/10))\n",
        "  random_index = random.randint(0, len(noise)-len(sig))\n",
        "  noisy_signal = sig + (required_rms/rms(noise)) * noise[random_index: random_index + len(sig)]\n",
        "  return noisy_signal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvgDlmexrWBh",
        "outputId": "d62f62bb-55de-4db7-e462-d940534ee941"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/ML CS433 Project 2/data/demand/DKITCHEN/ch05.wav',\n",
              " '/content/drive/MyDrive/ML CS433 Project 2/data/demand/OHALLWAY/ch05.wav',\n",
              " '/content/drive/MyDrive/ML CS433 Project 2/data/demand/SCAFE/ch05.wav']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "training_channels_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gADsGZQvgcLp",
        "outputId": "36e8af20-bd0a-4914-d5e5-a7c9f42ab655"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/ML CS433 Project 2/data/demand/DLIVING/ch05.wav',\n",
              " '/content/drive/MyDrive/ML CS433 Project 2/data/demand/OOFFICE/ch05.wav',\n",
              " '/content/drive/MyDrive/ML CS433 Project 2/data/demand/SPSQUARE/ch05.wav']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "val_environments_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9z5HN38sgqO",
        "outputId": "56f54895-3946-4dcc-8bdd-9ea1400ac853"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ID01': '/content/drive/MyDrive/ML CS433 Project 2/data/HC/ID01_hc_0_0_0_north.wav',\n",
              " 'ID15': '/content/drive/MyDrive/ML CS433 Project 2/data/HC/ID15_hc_0_0_0_north.wav',\n",
              " 'ID03': '/content/drive/MyDrive/ML CS433 Project 2/data/HC/ID03_hc_0_0_0_north.wav',\n",
              " 'ID10': '/content/drive/MyDrive/ML CS433 Project 2/data/HC/ID10_hc_0_0_0_north.wav',\n",
              " 'ID00': '/content/drive/MyDrive/ML CS433 Project 2/data/HC/ID00_hc_0_0_0_north.wav',\n",
              " 'ID08': '/content/drive/MyDrive/ML CS433 Project 2/data/HC/ID08_hc_0_0_0_north.wav',\n",
              " 'ID05': '/content/drive/MyDrive/ML CS433 Project 2/data/HC/ID05_hc_0_0_0_north.wav',\n",
              " 'ID09': '/content/drive/MyDrive/ML CS433 Project 2/data/HC/ID09_hc_0_0_0_north.wav',\n",
              " 'ID36': '/content/drive/MyDrive/ML CS433 Project 2/data/HC/ID36_hc_0_0_0_north.wav',\n",
              " 'ID30': '/content/drive/MyDrive/ML CS433 Project 2/data/PD/ID30_pd_2_1_1_north.wav',\n",
              " 'ID06': '/content/drive/MyDrive/ML CS433 Project 2/data/PD/ID06_pd_3_1_1_north.wav',\n",
              " 'ID34': '/content/drive/MyDrive/ML CS433 Project 2/data/PD/ID34_pd_2_0_0_north.wav',\n",
              " 'ID07': '/content/drive/MyDrive/ML CS433 Project 2/data/PD/ID07_pd_2_0_0_north.wav',\n",
              " 'ID02': '/content/drive/MyDrive/ML CS433 Project 2/data/PD/ID02_pd_2_0_0_north.wav',\n",
              " 'ID16': '/content/drive/MyDrive/ML CS433 Project 2/data/PD/ID16_pd_2_0_0_north.wav',\n",
              " 'ID24': '/content/drive/MyDrive/ML CS433 Project 2/data/PD/ID24_pd_2_0_0_north.wav',\n",
              " 'ID20': '/content/drive/MyDrive/ML CS433 Project 2/data/PD/ID20_pd_3_0_1_north.wav',\n",
              " 'ID04': '/content/drive/MyDrive/ML CS433 Project 2/data/PD/ID04_pd_2_0_1_north.wav'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "speaker_ID = []\n",
        "speaker_file = []\n",
        "\n",
        "\n",
        "def crawl_files(dir_name):\n",
        "  for root, dirs, files in os.walk(os.path.join(data_path,dir_name)):\n",
        "    for file in files:\n",
        "      ID = file.split(\"_\")[0]\n",
        "      if file.split(\".\")[0].endswith(\"north\"):\n",
        "        speaker_file.append(os.path.join(root, file))\n",
        "        speaker_ID.append(file.split(\"_\")[0])\n",
        "    \n",
        "crawl_files(\"HC\")\n",
        "crawl_files(\"PD\")\n",
        "\n",
        "#filenames = {}\n",
        "#for i, j in zip(speaker_ID, speaker_file)\n",
        "#    filenames.setdefault(i, []).append(j)\n",
        "\n",
        "filenames = dict(zip(speaker_ID, speaker_file))\n",
        "\n",
        "filenames\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPERghaWpRNW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfibSpC0OJyL"
      },
      "outputs": [],
      "source": [
        "noisy_data_path = os.path.join(data_path, \"noisy_data\")\n",
        "if not os.path.exists(noisy_data_path):\n",
        "    os.mkdir(noisy_data_path)\n",
        "    os.mkdir(os.path.join(noisy_data_path,\"test\"))\n",
        "    os.mkdir(os.path.join(noisy_data_path,\"train\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZxBxlfOpzU6"
      },
      "outputs": [],
      "source": [
        "## Functions from feature_extractor\n",
        "\n",
        "import torchaudio.compliance.kaldi as ta_kaldi\n",
        "from typing import Tuple\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def get_waveform(audio_path: str, normalization=True) -> Tuple[np.ndarray, int]:\n",
        "    \"\"\"Get the waveform and sample rate of a 16-bit mono-channel WAV or FLAC.\n",
        "    adapted from https://github.com/pytorch/fairseq/blob/master/fairseq/data/audio/audio_utils.py\n",
        "    Args:\n",
        "        path_or_fp (str): the path or file-like object\n",
        "        normalization (bool): Normalize values to [-1, 1] (Default: True)\n",
        "    Returns:\n",
        "        (numpy.ndarray): [n,] waveform array, (int): sample rate\n",
        "   \"\"\"   \n",
        "    waveform, sample_rate = sf.read(audio_path)\n",
        "    if normalization:\n",
        "        waveform = normalize_rms(waveform, rms_level = 0.1)\n",
        "    return waveform, sample_rate\n",
        "\n",
        "\n",
        "def normalize_rms(signal: np.ndarray, rms_level: float = 0.1) -> np.ndarray:\n",
        "    a = np.sqrt( (len(signal) * rms_level**2) / np.sum(signal**2) )\n",
        "    return signal * a\n",
        "\n",
        "\n",
        "def compute_mel_spectrograms(waveform: np.ndarray,sample_rate: int, options:dict) -> np.ndarray:\n",
        "    \"\"\"Compute mel spectrogram from waveform\n",
        "    Args:\n",
        "        waveform (np.ndarray): input waveform array\n",
        "        sample_rate (float): sample rate\n",
        "    \"\"\"    \n",
        "    waveform = torch.from_numpy(waveform).unsqueeze(0)\n",
        "    features = ta_kaldi.fbank(waveform, **options, sample_frequency=sample_rate)\n",
        "    return features.numpy()\n",
        "\n",
        "def compute_stft_spectrograms(waveform: np.ndarray,sample_rate: int, options:dict) -> np.ndarray:\n",
        "    \"\"\"Compute mel spectrogram from waveform\n",
        "    Args:\n",
        "        waveform (np.ndarray): input waveform array\n",
        "        sample_rate (float): sample rate\n",
        "    \"\"\"    \n",
        "    waveform = torch.from_numpy(waveform).unsqueeze(0)\n",
        "    features = ta_kaldi.spectrogram(waveform, **options, sample_frequency=sample_rate)\n",
        "    return features.numpy()\n",
        "\n",
        "\n",
        "def compute_noisy_mel_f(audio_f: str, noise_f: str, options:dict, snr):\n",
        "  signal, s_fs = get_waveform(audio_f)\n",
        "  noise, n_fs = get_waveform(noise_f)\n",
        "  if n_fs != s_fs:\n",
        "    raise(\"Error: sampling frequency not the same\")\n",
        "  \n",
        "  noisy_signal = get_noisy_signal(signal,noise,snr)\n",
        "  features = compute_mel_spectrograms(noisy_signal,s_fs,options)\n",
        "  return features.T\n",
        "\n",
        "def compute_noisy_stft_f(audio_f: str, noise_f: str, options:dict, snr):\n",
        "  signal, s_fs = get_waveform(audio_f)\n",
        "  noise, n_fs = get_waveform(noise_f)\n",
        "  if n_fs != s_fs:\n",
        "    print(n_fs,s_fs)\n",
        "    raise(\"Error: sampling frequency not the same\")\n",
        "  \n",
        "  noisy_signal = get_noisy_signal(signal,noise,snr)\n",
        "  features = compute_stft_spectrograms(noisy_signal,s_fs,options)\n",
        "  return features.T\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9VadnYLaBr1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "\n",
        "# Transform parameters\n",
        "options_mel = {\n",
        "    \"frame_length\" : 32, #ms\n",
        "    \"frame_shift\" : 4, #ms\n",
        "    \"window_type\" : \"hamming\",\n",
        "    \"num_mel_bins\" : 129,\n",
        "    \"channel\" : 0}\n",
        "\n",
        "options_stft = {\n",
        "    \"frame_length\" : 16, #ms\n",
        "    \"frame_shift\" : 8, #ms\n",
        "    \"window_type\" : \"hamming\",\n",
        "    \"channel\" : 0}\n",
        "\n",
        "# Paths to data\n",
        "hc_path = \"../../../data/HC/\"\n",
        "pd_path = \"../../../data/PD/\"\n",
        "chunks_path = \"../../../data/chunks/\"\n",
        "\n",
        "chunk_length = 500 #ms\n",
        "\n",
        "\n",
        "def divide_audio(feats, options):\n",
        "    \"\"\"\n",
        "    Divides spectrogram into 500 ms chunks\n",
        "\n",
        "    :param feats: the spectrogram extraction\n",
        "    :param options: the spectrogram options\n",
        "    :return: a list of 500 ms chunks of the spectrogram\n",
        "    \"\"\"\n",
        "    nb_frames_in_audio = feats.shape[1]\n",
        "    nb_frames_per_chunk = int(chunk_length*nb_frames_in_audio / (options[\"frame_shift\"]*(nb_frames_in_audio-1) + options[\"frame_length\"]))\n",
        "    \n",
        "    i = 0\n",
        "    chunks = []\n",
        "    while ((i+1)*nb_frames_per_chunk < nb_frames_in_audio): # while there still exists another extra 500 ms chunk\n",
        "        chunks.append(feats[:, i*nb_frames_per_chunk:(i+1)*nb_frames_per_chunk]) # append next chunk of 500 ms\n",
        "        i += 1\n",
        "        \n",
        "    return chunks\n",
        "\n",
        "def standardize(chunk):\n",
        "    \"\"\"\n",
        "    Standardizes a chunk \n",
        "\n",
        "    :param chunk: a chunk of spectrogram\n",
        "    :return: that chunk, standardized\n",
        "    \"\"\" \n",
        "    return (chunk-chunk.mean())/(chunk.std())\n",
        "\n",
        "def save_as_chunks(o_path, filename, feats, options, spec):\n",
        "    \"\"\"\n",
        "    Saves all standardized chunks from spectrogram to filesystem as csv files\n",
        "\n",
        "    :param speaker_path: path to speaker folder\n",
        "    :param filename: name of original audio file\n",
        "    :param feats: the spectrogram extraction\n",
        "    :param options: the spectrogram options\n",
        "    :param spec: the type spectrogram, 'mel' or 'stft'\n",
        "    \"\"\" \n",
        "    chunks = divide_audio(feats, options) # Get spectrogram chunks of 500ms\n",
        "    \n",
        "    # Name each chunk, standardize and store in filesystem\n",
        "    for i in range(len(chunks)):\n",
        "        chunk_filename = f'{spec}_{filename[:-4]}_chunk_{i}.csv' # get rid of '.wav' in original filename\n",
        "        stand = standardize(chunks[i])\n",
        "        np.savetxt(f'{o_path}/{chunk_filename}', stand, delimiter=\",\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXYk5hPMPjl5",
        "outputId": "5b15ca3b-1044-44b4-b865-29ecd0cd61b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished with left out speaker  ID05\n",
            "Finished with left out speaker  ID09\n",
            "Finished with left out speaker  ID10\n",
            "Finished with left out speaker  ID00\n",
            "Finished with left out speaker  ID36\n",
            "Finished with left out speaker  ID08\n",
            "Finished with left out speaker  ID01\n",
            "Finished with left out speaker  ID15\n",
            "Finished with left out speaker  ID24\n",
            "Finished with left out speaker  ID03\n",
            "Finished with left out speaker  ID02\n",
            "Finished with left out speaker  ID34\n",
            "Finished with left out speaker  ID04\n",
            "Finished with left out speaker  ID30\n",
            "Finished with left out speaker  ID06\n",
            "Finished with left out speaker  ID16\n",
            "Finished with left out speaker  ID20\n",
            "Finished with left out speaker  ID07\n"
          ]
        }
      ],
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "#initial architecture for noisification of the data including randomization. Deprecated\n",
        "\n",
        "random.seed(10)\n",
        "def create_one_out(speaker):\n",
        "  path = os.path.join(noisy_data_path,speaker)\n",
        "  test_noises, train_noises = get_channels()\n",
        "  if not os.path.exists(path):\n",
        "    os.mkdir(path)\n",
        "    os.mkdir(os.path.join(path,\"test\"))\n",
        "    os.mkdir(os.path.join(path,\"train\"))\n",
        "\n",
        "  \n",
        "  for snr in testing_SNR:\n",
        "    final_dir_m = os.path.join(path,\"test\", str(snr))\n",
        "    if not os.path.exists(final_dir_m):\n",
        "      os.makedirs(final_dir_m)\n",
        "\n",
        "    for noise in test_noises:\n",
        "      spec1 = \"mel_\" + os.path.basename(os.path.dirname(noise))\n",
        "      for file_ in filenames[speaker]:\n",
        "        #if not os.path.exists(os.path.join(final_dir_m,f'{spec1}_{os.path.basename(file_)[:-4]}_chunk_{0}.csv')):\n",
        "          #print(\"Creating \", os.path.join(final_dir_m,f'{spec1}_{os.path.basename(file_)[:-4]}_chunk_{0}.csv'))\n",
        "          mel_feats = compute_noisy_mel_f(file_,noise,options_mel,snr)\n",
        "          save_as_chunks(final_dir_m,os.path.basename(file_),mel_feats,options_mel,spec1)\n",
        "            \n",
        "\n",
        "\n",
        "  other_speakers = list(filenames.keys())\n",
        "  other_speakers.remove(speaker)\n",
        "  for train_speaker in other_speakers:\n",
        "    for tr_noise in train_noises:\n",
        "      snr = 10\n",
        "      dir_m = os.path.join(path,\"train\")\n",
        "      if not os.path.exists(dir_m):\n",
        "        os.makedirs(dir_m)\n",
        "    \n",
        "      spec1 = \"mel_\" + os.path.basename(os.path.dirname(tr_noise))\n",
        "    \n",
        "      for file_ in filenames[train_speaker]:\n",
        "        \n",
        "        #if not os.path.exists(os.path.join(dir_m,f'{spec1}_{os.path.basename(file_)[:-4]}_chunk_{0}.csv')):\n",
        "          #print(\"Creating mel train chunks\")\n",
        "          mel_feats = compute_noisy_mel_f(file_,tr_noise,options_mel,snr)\n",
        "          save_as_chunks(dir_m,os.path.basename(file_),mel_feats,options_mel,spec1)\n",
        "        \n",
        "      \n",
        "  print(\"Finished with left out speaker \", speaker)\n",
        "\n",
        "      \n",
        "  \n",
        "with Pool(8) as p:\n",
        "  p.map(create_one_out,filenames.keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnvJuhdvGZKm",
        "outputId": "00f2d759-af48-4ad3-dfc2-9b32470aa3ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'noise_path': '/content/drive/MyDrive/ML CS433 Project 2/data/demand/DLIVING/ch05.wav',\n",
              "  'out_path': '/content/drive/MyDrive/ML CS433 Project 2/data/noisy_data/test',\n",
              "  'SNRs': [5, 10, 15]},\n",
              " {'noise_path': '/content/drive/MyDrive/ML CS433 Project 2/data/demand/OOFFICE/ch05.wav',\n",
              "  'out_path': '/content/drive/MyDrive/ML CS433 Project 2/data/noisy_data/test',\n",
              "  'SNRs': [5, 10, 15]},\n",
              " {'noise_path': '/content/drive/MyDrive/ML CS433 Project 2/data/demand/SPSQUARE/ch05.wav',\n",
              "  'out_path': '/content/drive/MyDrive/ML CS433 Project 2/data/noisy_data/test',\n",
              "  'SNRs': [5, 10, 15]},\n",
              " {'noise_path': '/content/drive/MyDrive/ML CS433 Project 2/data/demand/DKITCHEN/ch05.wav',\n",
              "  'out_path': '/content/drive/MyDrive/ML CS433 Project 2/data/noisy_data/train',\n",
              "  'SNRs': [10]},\n",
              " {'noise_path': '/content/drive/MyDrive/ML CS433 Project 2/data/demand/OHALLWAY/ch05.wav',\n",
              "  'out_path': '/content/drive/MyDrive/ML CS433 Project 2/data/noisy_data/train',\n",
              "  'SNRs': [10]},\n",
              " {'noise_path': '/content/drive/MyDrive/ML CS433 Project 2/data/demand/SCAFE/ch05.wav',\n",
              "  'out_path': '/content/drive/MyDrive/ML CS433 Project 2/data/noisy_data/train',\n",
              "  'SNRs': [10]}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "random.seed(10)\n",
        "\n",
        "train_path = os.path.join(noisy_data_path, \"train\")\n",
        "test_path = os.path.join(noisy_data_path, \"test\")\n",
        "\n",
        "\n",
        "\n",
        "training_SNR = [10]\n",
        "testing_SNR = [5, 10, 15]\n",
        "\n",
        "test_noises_p, train_noises_p = get_channels()\n",
        "test_noises = [{\"noise_path\": noise, \"out_path\": test_path, \"SNRs\": testing_SNR} for noise in test_noises_p]\n",
        "train_noises = [{\"noise_path\": noise, \"out_path\": train_path, \"SNRs\": training_SNR} for noise in train_noises_p]\n",
        "\n",
        "noises = test_noises + train_noises\n",
        "noises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX2V7iAPGZKm",
        "outputId": "4a1c1431-3fa1-4d2f-b842-d94a0f8ea767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating chunks for Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID15_hc_0_0_0_north.wav \n",
            "/content/drive/MyDrive/ML CS433 Project 2/data/HC/ID08_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID05_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID03_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID30_pd_2_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID10_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID06_pd_3_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID00_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID34_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID05_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID07_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID09_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID36_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID02_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID16_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID30_pd_2_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID06_pd_3_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID24_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID20_pd_3_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID04_pd_2_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID04_pd_2_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID15_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID08_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID03_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID05_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID10_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID30_pd_2_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID00_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID06_pd_3_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID05_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID34_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID09_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID07_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID36_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID02_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID30_pd_2_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID16_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID06_pd_3_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID24_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID04_pd_2_0_1_north.wav\n",
            "Creating chunks for /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID20_pd_3_0_1_north.wav \n",
            "Creating chunks for /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID15_hc_0_0_0_north.wav \n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID04_pd_2_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID15_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID03_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID08_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID10_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID05_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID00_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID30_pd_2_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID05_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID06_pd_3_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID09_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID34_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID36_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID07_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID30_pd_2_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID02_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID06_pd_3_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID04_pd_2_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID16_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID03_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID24_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID10_hc_0_0_0_north.wavCreating chunks for \n",
            " /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID20_pd_3_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID08_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID04_pd_2_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID01_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID30_pd_2_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID15_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID06_pd_3_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID07_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID03_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID02_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID10_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID00_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID16_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID08_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID24_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID05_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID20_pd_3_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID09_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID04_pd_2_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID36_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID03_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID30_pd_2_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID10_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID06_pd_3_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID08_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID34_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID07_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID30_pd_2_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID02_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID06_pd_3_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID16_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID07_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID24_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID02_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID20_pd_3_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID16_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID04_pd_2_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID01_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID24_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID20_pd_3_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID15_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID04_pd_2_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID03_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID03_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID10_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID10_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID00_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID08_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID08_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID30_pd_2_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID05_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID06_pd_3_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID09_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID36_hc_0_0_0_north.wav\n",
            "Creating chunks for \n",
            " /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID07_pd_2_0_0_north.wavCreating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID30_pd_2_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID02_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID06_pd_3_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID16_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID34_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID24_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID07_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID20_pd_3_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID02_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID04_pd_2_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID16_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID01_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID24_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID20_pd_3_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID15_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID04_pd_2_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID03_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID10_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID00_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID08_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID05_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID09_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/HC/ID36_hc_0_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID30_pd_2_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID06_pd_3_1_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID34_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID07_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID02_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID16_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID24_pd_2_0_0_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID20_pd_3_0_1_north.wav\n",
            "Creating chunks for  /content/drive/MyDrive/ML CS433 Project 2/data/PD/ID04_pd_2_0_1_north.wav\n"
          ]
        }
      ],
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "\n",
        "def add_noisy_data(noise):\n",
        "    spec1 = \"mel_\" + os.path.basename(os.path.dirname(noise[\"noise_path\"]))\n",
        "    for snr in noise[\"SNRs\"]:\n",
        "        out_path = os.path.join(noise[\"out_path\"], str(snr))\n",
        "        if not os.path.exists(out_path):\n",
        "            os.mkdir(out_path)\n",
        "        \n",
        "        for file_ in filenames.values():\n",
        "            if not os.path.exists(os.path.join(out_path,f'{spec1}_{os.path.basename(file_)[:-4]}_chunk_{0}.csv')):\n",
        "                print(\"Creating chunks for \", file_)\n",
        "                mel_feats = compute_noisy_mel_f(file_,noise[\"noise_path\"],options_mel,snr)\n",
        "                save_as_chunks(out_path,os.path.basename(file_),mel_feats,options_mel,spec1)\n",
        "                \n",
        "with Pool(2) as p:\n",
        "    p.map(add_noisy_data,noises)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBh2WqM6GZKn",
        "outputId": "6e40c5f2-89ed-42d5-c803-056814f675fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "os.path.exists(os.path.join(noisy_data_path, \"test\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GajWgJoeGZKn",
        "outputId": "d36d21b6-a2c0-49cf-b7ae-07971e22b708"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/alex/ml-project-2-masters_of_loss/data/noisy_data/test'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.path.join(noisy_data_path, \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deZ1ZWsuGZKn",
        "outputId": "212aa9c6-e09c-48d8-f1f8-151b03eae3b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'/home/alex/ml-project-2-masters_of_loss/data/noisy_data/test' == '/home/alex/ml-project-2-masters_of_loss/data/noisy_data/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMvhnD4XGZKo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}